{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca8851cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c6/kh1v5smn18l3tbcsjpvvqv1h0000gn/T/ipykernel_791/1362822283.py:6: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, header=None, encoding='latin1', names=column_names)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "file_path = 'training.1600000.processed.noemoticon.csv'\n",
    "column_names = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
    "try:\n",
    "    df = pd.read_csv(file_path, header=None, encoding='latin1', names=column_names)\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset file not found.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79811a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataFrame after converting to lowercase:\n",
      "                                                text  \\\n",
      "0                                 text of the tweet    \n",
      "1  is upset that he can't update his Facebook by ...   \n",
      "2  @Kenichan I dived many times for the ball. Man...   \n",
      "3    my whole body feels itchy and like its on fire    \n",
      "4  @nationwideclass no, it's not behaving at all....   \n",
      "\n",
      "                                          text_lower  \n",
      "0                                 text of the tweet   \n",
      "1  is upset that he can't update his facebook by ...  \n",
      "2  @kenichan i dived many times for the ball. man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n"
     ]
    }
   ],
   "source": [
    "# Convert text to lowercase\n",
    "df['text_lower'] = df['text'].str.lower()\n",
    "print(\"Sample DataFrame after converting to lowercase:\")\n",
    "print(df[['text', 'text_lower']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54ca1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# Remove punctuation\n",
    "punctuation = string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', punctuation)\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b34a2bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample DataFrame after removing punctuation:\n",
      "                                          text_lower  \\\n",
      "0                                 text of the tweet    \n",
      "1  is upset that he can't update his facebook by ...   \n",
      "2  @kenichan i dived many times for the ball. man...   \n",
      "3    my whole body feels itchy and like its on fire    \n",
      "4  @nationwideclass no, it's not behaving at all....   \n",
      "\n",
      "                            text_without_punctuation  \n",
      "0                                 text of the tweet   \n",
      "1  is upset that he cant update his facebook by t...  \n",
      "2  kenichan i dived many times for the ball manag...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  nationwideclass no its not behaving at all im ...  \n"
     ]
    }
   ],
   "source": [
    "df['text_without_punctuation'] = df['text_lower'].apply(remove_punctuation)\n",
    "print(\"\\nSample DataFrame after removing punctuation:\")\n",
    "print(df[['text_lower', 'text_without_punctuation']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6268bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Download stopwords if not already downloaded\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3d81e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد stop words انگلیسی: 198\n",
      "نمونه‌ای از stop words: [\"wasn't\", 'out', 'which', 'he', 'wouldn', 'ma', \"you'll\", \"i'd\", 'ain', 'between']\n"
     ]
    }
   ],
   "source": [
    "# Get the set of English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(f\"تعداد stop words انگلیسی: {len(stop_words)}\")\n",
    "print(f\"نمونه‌ای از stop words: {list(stop_words)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03d46004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stop words from text (using a for loop)\n",
    "def remove_stopwords_loop(text):\n",
    "    words = [word.lower() for word in text.split()] \n",
    "    filtered_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_words.append(word)\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdbb53f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           text tweet\n",
      "1    upset cant update facebook texting might cry r...\n",
      "2    kenichan dived many times ball managed save 50...\n",
      "3                     whole body feels itchy like fire\n",
      "4             nationwideclass behaving im mad cant see\n",
      "Name: text_without_stopwords, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['text_without_stopwords'] = df['text_without_punctuation'].apply(remove_stopwords_loop)\n",
    "print(df['text_without_stopwords'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e922e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('your_processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11f9882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شکل ماتریس ویژگی TF-IDF: (1048573, 591035)\n",
      "تعداد ویژگی‌ها (اندازه واژگان): 591035\n",
      "نمونه‌ای از ویژگی‌های تبدیل شده (به صورت sparse matrix):\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 37 stored elements and shape (5, 591035)>\n",
      "  Coords\tValues\n",
      "  (0, 517253)\t0.7534146107026727\n",
      "  (0, 541552)\t0.6575457583923267\n",
      "  (1, 550511)\t0.3020468584078402\n",
      "  (1, 83797)\t0.17495340835001688\n",
      "  (1, 549986)\t0.2949660103614437\n",
      "  (1, 161552)\t0.29947321881330696\n",
      "  (1, 517306)\t0.37419561316878136\n",
      "  (1, 350558)\t0.2638174305613934\n",
      "  (1, 113645)\t0.28353584892889\n",
      "  (1, 445340)\t0.37888949897909924\n",
      "  (1, 463932)\t0.22717498271163797\n",
      "  (1, 530767)\t0.1785791673814293\n",
      "  (1, 27415)\t0.2618772750164461\n",
      "  (1, 64277)\t0.34032237888179545\n",
      "  (2, 295449)\t0.4122176774879551\n",
      "  (2, 134058)\t0.45446374473680956\n",
      "  (2, 335713)\t0.20905810569952854\n",
      "  (2, 527996)\t0.21530677127381898\n",
      "  (2, 50850)\t0.27479542712155597\n",
      "  (2, 334491)\t0.2818731460234196\n",
      "  (2, 462234)\t0.2531635544933253\n",
      "  (2, 8929)\t0.2727317711455338\n",
      "  (2, 445127)\t0.22750842771309512\n",
      "  (2, 188335)\t0.13547728195243214\n",
      "  (2, 70485)\t0.4122176774879551\n",
      "  (3, 568014)\t0.3769903865581114\n",
      "  (3, 67573)\t0.42346785189792135\n",
      "  (3, 165764)\t0.3807476903968572\n",
      "  (3, 265578)\t0.5126325337446265\n",
      "  (3, 316628)\t0.2335466960437135\n",
      "  (3, 168639)\t0.4650249984923549\n",
      "  (4, 83797)\t0.20834198092105732\n",
      "  (4, 374103)\t0.6596896554085342\n",
      "  (4, 56994)\t0.5624377640874441\n",
      "  (4, 257971)\t0.16357754364789104\n",
      "  (4, 331267)\t0.34943058154118484\n",
      "  (4, 466982)\t0.23708140998207264\n",
      "\n",
      "نمونه‌ای از نام ویژگی‌ها (کلمات واژگان): ['00' '000' '0000' '0000000000' '00000001' '0000001' '0000014' '0001'\n",
      " '0001110101001010000111' '0001am' '0001t' '0003' '0005' '00055' '0005am'\n",
      " '0005mm' '0006' '0007' '0009' '000aah']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ایجاد یک شیء از TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# آموزش و تبدیل متن پیش‌پردازش شده به ماتریس ویژگی TF-IDF\n",
    "X = tfidf_vectorizer.fit_transform(df['text_without_stopwords'])\n",
    "\n",
    "# حالا X شامل ماتریس ویژگی TF-IDF برای توییت‌های شماست\n",
    "print(\"شکل ماتریس ویژگی TF-IDF:\", X.shape)\n",
    "print(\"تعداد ویژگی‌ها (اندازه واژگان):\", len(tfidf_vectorizer.vocabulary_))\n",
    "print(\"نمونه‌ای از ویژگی‌های تبدیل شده (به صورت sparse matrix):\")\n",
    "print(X[:5])\n",
    "\n",
    "# برای اینکه بفهمیم هر ستون در ماتریس X مربوط به چه کلمه‌ای است:\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(\"\\nنمونه‌ای از نام ویژگی‌ها (کلمات واژگان):\", feature_names[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "037afe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شکل X_train: (838858, 591035)\n",
      "شکل X_test: (209715, 591035)\n",
      "شکل y_train: (838858,)\n",
      "شکل y_test: (209715,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# فرض کنید X ماتریس ویژگی TF-IDF و y ستون احساسات (sentiment) باشه\n",
    "# اگر ستون احساسات شما اسم دیگه‌ای داره، اون رو جایگزین کنید\n",
    "y = df['sentiment']\n",
    "\n",
    "# تقسیم داده‌ها به آموزش و تست\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"شکل X_train:\", X_train.shape)\n",
    "print(\"شکل X_test:\", X_test.shape)\n",
    "print(\"شکل y_train:\", y_train.shape)\n",
    "print(\"شکل y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0a1e8be",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m naive_bayes_model \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# آموزش مدل با استفاده از داده‌های آموزشی\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mnaive_bayes_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mمدل Naive Bayes با موفقیت آموزش داده شد.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:739\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    736\u001b[0m _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    738\u001b[0m labelbin \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n\u001b[0;32m--> 739\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mlabelbin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m labelbin\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:335\u001b[0m, in \u001b[0;36mLabelBinarizer.fit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit label binarizer/transform multi-class labels to binary labels.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    The output of transform is sometimes referred to as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m        will be of CSR format.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:312\u001b[0m, in \u001b[0;36mLabelBinarizer.fit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has 0 samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_input_ \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39missparse(y)\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/multiclass.py:73\u001b[0m, in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_labels\u001b[39m(\u001b[38;5;241m*\u001b[39mys):\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract an ordered array of unique labels.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    We don't allow:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    array([ 1,  2,  5, 10, 11])\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     ys \u001b[38;5;241m=\u001b[39m \u001b[43mattach_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     xp, is_array_api_compliant \u001b[38;5;241m=\u001b[39m get_namespace(\u001b[38;5;241m*\u001b[39mys)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ys) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_unique.py:56\u001b[0m, in \u001b[0;36mattach_unique\u001b[0;34m(return_tuple, *ys)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattach_unique\u001b[39m(\u001b[38;5;241m*\u001b[39mys, return_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Attach unique values of ys to ys and return the results.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    The result is a view of y, and the metadata (unique) is not attached to y.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        Input data with unique values attached.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_attach_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_tuple:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_unique.py:56\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattach_unique\u001b[39m(\u001b[38;5;241m*\u001b[39mys, return_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Attach unique values of ys to ys and return the results.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    The result is a view of y, and the metadata (unique) is not attached to y.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        Input data with unique values attached.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_attach_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_tuple:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_unique.py:23\u001b[0m, in \u001b[0;36m_attach_unique\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m unique \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m unique_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(y\u001b[38;5;241m.\u001b[39mdtype, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique\u001b[39m\u001b[38;5;124m\"\u001b[39m: unique})\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\u001b[38;5;241m.\u001b[39mview(dtype\u001b[38;5;241m=\u001b[39munique_dtype)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/_arraysetops_impl.py:286\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    284\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/_arraysetops_impl.py:353\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[0m\n\u001b[1;32m    351\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     ar\u001b[38;5;241m.\u001b[39msort()\n\u001b[1;32m    354\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    355\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# ایجاد یک شیء از مدل MultinomialNB\n",
    "naive_bayes_model = MultinomialNB()\n",
    "\n",
    "# آموزش مدل با استفاده از داده‌های آموزشی\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"مدل Naive Bayes با موفقیت آموزش داده شد.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
